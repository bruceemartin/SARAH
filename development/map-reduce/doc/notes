Statistics:
	DONE: input format is given by user -- mapreduce.inputformat.class
	DONE: input key type is implied from input format
	DONE: input value type implied from input format
	DONE: map output key type / reducer input key type is FunctionKey
	DONE: map output value type / reducer input value type is LongWritable
	DONE: combiner is LongSumReducer -- good idea regardless, why ship a bunch of ones
	DONE:  number of reducers is number of functions
	DONE:  partitioner maps one function to one reducer, 1 reducer per function
		Having all the keys of a function sorted and together makes generating 
		the interval file simpler.
			Balance simply generates sequence file by adding up values
			Could do this in a map-only job -- one mapper per function
			Need total number of values per function to determine number 
			of reducers and intervals
		Does this scale? 
			no if number of different keys in one function in sample is huge
		How to deal with this?
			Generate distribution in multiple files per function
			Balance mapper uses a total order partitioner on number of keys
			Mapper output is key:count -- all reducers have TOS, We don't really
			have a nice way to generate the sequence file because we need to
			process the keys in sorted order, not in parallel, unless we somehow
			had the accumulated count in previous partitions -- to hard.

		Incremental update?  If there is a new file, how easy is it to add to count?
			Original file already sorted and combined, 
			New file mapped and combined
			Partitioner maps both to same reducer per function
			If we somehow supported multiple total sort,
			we would still need to process original files since count code change

		Need total number of keys per function and 
		total number of values per function to calculate
			DONE:  Define counters in statistics job, 
			       Reducer can increment, 
				sarah.sample.number.records
				sarah.<function>.number.keys
				sarah.<function>.number.values
			DONE:  driver save statistics in HDFS
			DONE:  change reducer to use Metrics class
			 

	Generated sample:
	   DONE: sample output format is given by user -- sarah.random.sample.outputformat.class
	   DONE: sample output key type is given by user -- sarah.random.sample.output.key.class
	   DONE: sample output value type is given by user -- sarah.random.sample.output.value.class
	   DONE: sarah.sample.size should be actual % of records
		 need an input property sarah.target.sample.size for desired sample size

	For each function:
	   DONE: output file format is SequenceFile
	   DONE: output key type is FunctionKey where functionName is <function> and 
	   	 functionKey is -- sarah.<function>.output.key.class -- do we need output?
	   DONE: output value type is LongWritable -- we are counting keys.
	
	   DONE BUG:  Function output records are being double counted for total number of records after 
			applying function or records associated with key are being half counted.  
			Statistics produce this:
				sarah.sample.EveningFilter.number.keys=12
				sarah.sample.EveningFilter.number.records=30050
				sarah.sample.IPFromLog.number.keys=20374
				sarah.sample.IPFromLog.number.records=90910
			BUT when adding up all of the counts for all of the keys in the functions files,
			the sum of the counts are exactly 1/2 of the above number of records.

	DONE: Seed should be included in statistics. 
	DONE: Generate output statistics in client output, not just counters.
	DONE: Statistics.xml file should have same order as client output.
	DONE: Make Metrics an object so that it can be extended.
			Invisioned extensions -- save generated statistics somewhere else
				      -- different kinds of properties -- not just current ones
				      -- calculating statistics in some way other than hadoop counters
			                 e.g. can this class be reused in Sarah for Spark?

	DONE: Add descriptions to properties and reports
		Define Metric class with property name and description
		Change PropertyNames to be MetricNames
		Change uses of PropertyNames to use MetricNames
		Make reports and statistics.xml use descriptions
		Remove use of configuration from client code
		

	DONE: Make PropertyNames be part of statistics and make balance generated property names part of
		balance -- this becomes a specification for statistics and balance.  Will Metrics work with
		BalancePropertyNames?
	

	DONE: Change name of sarah.target.sample.size and sarah.sample.size to something more descriptive
		sarah.sample.target.factor?  sarah.sample.factor?  Look at APIs that generate samples for
		appropriate term.

	DONE: Add properties for program and version and date/time that generated statistics -- easy
	
	DONE: Compute record sizes 
		done	Turn record to bytes in MultiFunctionMapper as in FunctionKey 
		done	Make FunctionKey have extra record size 
			  -- used for comparison (want them sorted), but not for partitioning
			  -- reduce call has all records for a key of the same size
			  -- multiple reduce calls has all records for the key
			  -- 1 reducer has all records for the function.
		done 	Update reducer to generate statistics as per function as counters/properties
				sarah.sample.%func.min.size.record
				sarah.sample.%func.max.size.record
				sarah.sample.%func.total.size.record
				sarah.sample.%func.mean.size.record
				sarah.sample.%func.quantile25.size.record
				sarah.sample.%func.quantile50.size.record
				sarah.sample.%func.quantile75.size.record
		  
	DONE: make all statistics be reported via SarahMetrics
	      for SarahMapReduceMetrics support property,counter and file output
	      MultipleOutputs found in MultiFunctionMapper,MultiFunctionReducer and Statistics
	      
	      
	      				
				
	TODO: input statistics -- use identity mapper?
		number of records  -- done
		distribution of keys -- treat it like a function -- identity mapper
		record size -- min, max, distribution -- do this for a function on the sample
		estimated statistics based on sample statistics -- can be done at client -- properties:
		
	TODO:  when saving/printing sample statistics -- generate estimated version -- do the multiplication!
	
	TODO:  StatsForFunctionAndKey make it into reducer's output file, 
	       but are not named as in the SarahMetricNames class	

	TODO:  Update reducer to generate statistics per function.key as values in output file
			Besides number of records associated with the key, it is
			interesting to know statistics about the records associated with the key.

			Balancing -- we can do it based on number of records per reducer
				If we want to balance the number of bytes per reducer, then we 
				actually need the function.key record data
				To do both, we need sorted array of record sizes AND
				per key a sorted array of record sizes
				First sorted by key.size with comparator -- generate %
				Sort globally to generate global %
		
			done mapper outputs (function,key,recsize), 1
			done partitioner -- by function -- one reducer per function
			done combiner is longSumReducer -- adds up  the instances of records of same size output for key
			done compareTo -- sort on (function, key, recsize)
			
			     Array funckeyrecsize
			     Array funcrecsize
			     FunctionKey prevKey
			     long minRecSizeFuncKey, maxRecSizeFuncKey
			     long minRecSizeFunc, maxRecSizeFunc

			     setup: initializeFunc(), initializeFuncRecKey()

	DONE: SarahMetrics doubles are not being divided by factor

	TODO: man page for statistics
	TODO: javadoc for statistics.

	TODO: incremental update of statistics -- could support addition only
	TODO: Input data sets that are not directories -- needed for incremental update too.
		An input property with all of the files and directories
		Convert into list of files and dates and sizes
		Compare input property to stored property
	????: output seed, even if not given -- needed for incremental update. Not really random since
		all mappers have same pseudo random number sequence.  Probably best solution is to always
		let Java assign the key.


    FIXED: MapReduce counter names have a limit of 64 characters.  This is causing troubles in using them
          for metrics.  Need to see if that can be bumped up, worked around or somehow dealt with.  For some odd
          reason this is only a problem when running in a cluster.  It does not show up when running in Eclipse.
		  Now uses symbols for counter names.


Balance:
	For each function
	   DONE: input file format is SequenceFile -- 1 per function, 1 mapper per file
	   DONE: mapper needs function counter values:
		sarah.<function>.number.keys
		sarah.<function>.number.values
		Driver can read all of these and pass to all mappers.
	   DONE: input key type is FunctionKey where functionName is <function> and 
	   	functionKey is -- sarah.<function>.output.key.class -- do we need output?
	   
	DONE: input value type is LongWritable -- we are counting keys.
	DONE: mapper, not reducer produces interval for function -- no need for reducer
	FIXED BUG:  mapper saving prevKey upon each function call -- this is a problem since one
		Hadoop reuses objects.  What did old reducer do?
	FIXED BUG:  Last bucket not handled correctly -- looks like number of reducers needs to be +1, 
                 but edge case of last key needs to be handled.
	TODO??: Need to overwrite functions and preferred number of records -- add comment in text file
	
	DONE:  BalanceMetricService needs to overwrite save() and print() to produce correct output

	DONE: ouput file format is SequenceFile -- that's what the TotalOrderPartitioner wants
	        output key is sarah.<function>.output.key.class -- we do need this so that multifile
		output can be set up, or is SequenceFile of FunctionKey enough?
	   	output value type is NullWritable

 	DONE: make all configuration needed for balance in stats file -- no need for extra config
		sarah.sample.size
		sarah.functions
		sarah.%func.output.key.class
	DONE: move code to read metrics to Metrics class
	DONE: have balance use Metrics.print

	TODO: sarah.partition.preferredSize -- as parameter, rather than configuration?
	TODO: sarah.%func.partion.preferredSize -- per function?
	TODO: run balance for some functions, not all
	DONE: make it "balance" everywhere instead of balance-reducers
	TODO: update balance to offer option to use record sizes per key, per reducer

	TODO: man page for balance
	TODO: javadoc for balance
	DONE: move balance properties to BalancePropertyNames.  
		Use SarahMapReduceMetrics just like statistics does for balance results.
	DONE: Get results into balance tool report

Visualize:
	TODO: Implement tool that generates R or zeplin? graphics from statistics, balance	   

Tests:
	TODO: update tests for weblog
	TODO: update tests for shakespeare
	TODO: update tests for shakespeare_linenumbers

	
Spark:
	DONE:  refactor common code into sarah.common package
		   use it in Spark for SARAH.


Refactoring TODO
	TODO:	Make sure SarahMetric hierarchy has correct visibility and overrides
	
	DONE:	Implement CountedDoubleMapReduceMetric completely and correctly
	
	DONE:	Set metric values from counters (for client after job runs)
			Still needs to implement setLong / setDouble in MapReduceBase
			Need to understand how to have dynamically named properties too.
	
	DONE:	Set metric values from configuration (for client startup and task startup)
	
	DONE:   Put save functionality to files in base -- let different subclasses reuse or change
			
	DONE:	Make sure service and metrics are completely implemented.
	
	TODO:	Move MultiFileOutput from client/reducer into MapReduceMetricService
	
	DONE:   BalanceSarahMetrics needs BalanceSarahMetricService
	
		    Check defaults for setLong when obtained from configuration -- seed in particular and others
	
	value is 2.7, increment by 1 should be 3.7
	counter value should be 27000 and then 37000
	
	
	How do base metrics work?
	SARAH computes and stores a set of base metrics.  
	The base metrics are defined in the singleton SarahMetrics class.
	Tools can depend on the base metrics at compile time by using the members of SarahMetrics.
	Each base metric is a member of that SarahMetrics.
	Each base metric is an instance of SarahMetric or subclass.
	A SarahMetric represents a single metric or a class of metrics, distinguished by function name.
		The metrics that can be distinguished by function name are limited to a set of function names.
		The constructor to SarahMetrics takes an array of function names.
	Some of the base SarahMetrics are CountedDoubleSarahMetric or CountedLongSarahMetric.
	These metrics are counted, that is tools can increment them.
	SARAH base metrics can be saved in a file by invoking SarahMetricService.save()
		SarahMetricServiceBase constructor is given a FileSystem.
	SARAH base metrics can be "pretty printed" as XML or Java properties by invoking SarahMetricService.print()
	SARAH base metrics are "grouped" for ease of understanding and presentation.
		The groups are members of SarahMetrics.  They are arrays of SarahMetric.
		The groups are:
			functionMetrics
			inputDataSetMetrics
			sampleMetrics
			sampleFunctionMetrics
			sampleFunctionKeyMetrics
			extendedMetrics
	SARAH base metrics can be read from a file.  
		This is to pass values from one tool to another.
		SARAHMetrics 
	SARAH base metrics does not define how metrics are shared between processes
	
	Supported extensions:
	Subclasses can change the base behavior of using the file system to store metrics.
		Implement SarahMetricService to use something other than the file system.
	Subclasses can extend the SarahMetric and Counted*SarahMetric classes.
		Extend the classes and replace the metric instances in SarahMetrics
	Subclasses can add additional extended metrics.
		Extended metrics should be added to the extendedMetrics group.
		The additional metrics will be saved, printed and read by the base classes.
	Subclasses can define how metrics are shared between processes
	
	
	
	
	
	DONE:	Inputs / Outputs per tool
			
			Statistics
			    Input -- 
			    	properties set in configuration
			    Output -- 												
			    	properties set in configuration, 			statistics.xml, console
			    	tool properties, 
			    	input data set metrics
			    	sample metrics
			    	per function metrics
			    	
			    	random sample								./samples/random
			    	
			    	results of applying each function			./functions/<function>
			    	
			Balance
				Input
					properties set in configuration
					statistics.xml
					./functions/<function>
					
				Output
					properties									console, ./artifacts/balanced-reducers/<function>/balanced.xml
					number of reducers property					
					where to find sequence files				
			
					interval sequence file per function?		./artifacts/balanced-reducers/<function>/interval-m-*
					text version of sequence file per function	./artifacts/balanced-reducers/<function>-txt/interval-m-*
		
	